{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzE2bIZqNres",
        "outputId": "19d33a4a-4fe3-47fc-ea63-939cfe56c811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16209, 22) (5404, 21)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "# Load your data\n",
        "df_train = pd.read_csv(\"/content/train_with_images.csv\")\n",
        "df_test = pd.read_csv(\"/content/test_with_images.csv\")\n",
        "\n",
        "print(df_train.shape, df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your processed data (with image_path)\n",
        "df_train = pd.read_csv(\"/content/train_with_images.csv\")\n",
        "df_test = pd.read_csv(\"/content/test_with_images.csv\")\n",
        "\n",
        "print(f\"Train: {df_train.shape}, Test: {df_test.shape}\")\n",
        "print(\"Columns:\", df_train.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn9fto3wmKu7",
        "outputId": "c6f2ccff-f5dd-4857-9e27-f4818008f836"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train: (16209, 22), Test: (5404, 21)\n",
            "Columns: ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'sale_year', 'sale_month', 'image_path']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ← CRITICAL: REPLACE WITH YOUR EXACT PATH FROM FILES PANEL\n",
        "IMAGE_BASE_PATH = \"/content/drive/MyDrive/images\"\n",
        "\n",
        "# Create image_path column\n",
        "df_train[\"image_path\"] = IMAGE_BASE_PATH + \"/\" + df_train.index.astype(str) + \".png\"\n",
        "df_test[\"image_path\"] = IMAGE_BASE_PATH + \"/\" + df_test.index.astype(str) + \".png\"\n",
        "\n",
        "# Test 3 images exist\n",
        "for i in [0, 1, 100]:\n",
        "    path = df_train.iloc[i][\"image_path\"]\n",
        "    status = \"OK\" if os.path.exists(path) else \"MISSING\"\n",
        "    print(f\"Row {i}: {status}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJIL6grSmX3h",
        "outputId": "4b94a36a-69a4-452b-8a82-f20f13567080"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 0: OK\n",
            "Row 1: OK\n",
            "Row 100: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only rows with existing images\n",
        "valid_mask = [os.path.exists(p) for p in df_train['image_path']]\n",
        "df_train_valid = df_train[valid_mask].reset_index(drop=True)\n",
        "\n",
        "tabular_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
        "                   'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
        "                   'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "                   'lat', 'long', 'sqft_living15', 'sqft_lot15', 'sale_year', 'sale_month']\n",
        "\n",
        "X_tab = df_train_valid[tabular_features].values\n",
        "y = df_train_valid['price'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_tab_scaled = scaler.fit_transform(X_tab)\n",
        "\n",
        "print(f\"Valid images: {len(df_train_valid)}/{len(df_train)}\")\n",
        "print(\"Tabular shape:\", X_tab_scaled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYf8whtjmkCp",
        "outputId": "ec5d9b3e-6037-49ad-ed7d-78c8010faaf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid images: 16209/16209\n",
            "Tabular shape: (16209, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class HouseDataset(Dataset):\n",
        "    def __init__(self, df, tabular_data, transform=None):\n",
        "        self.df = df\n",
        "        self.tabular = tabular_data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.iloc[idx]['image_path']\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        tabular = torch.FloatTensor(self.tabular[idx])\n",
        "        price = torch.FloatTensor([self.df.iloc[idx]['price']])\n",
        "        return image, tabular, price\n",
        "\n",
        "dataset = HouseDataset(df_train_valid, X_tab_scaled, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "print(\"Dataset ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSjJNM95mpy9",
        "outputId": "fba9c407-e834-4002-98a8-83fc692f8e38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self, tabular_size=20):\n",
        "        super().__init__()\n",
        "        self.cnn = resnet18(weights='IMAGENET1K_V1')\n",
        "        self.cnn.fc = nn.Identity()\n",
        "\n",
        "        self.tabular_net = nn.Sequential(\n",
        "            nn.Linear(tabular_size, 128), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(512 + 64, 256), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular):\n",
        "        img_feat = self.cnn(image)\n",
        "        tab_feat = self.tabular_net(tabular)\n",
        "        combined = torch.cat([img_feat, tab_feat], dim=1)\n",
        "        return self.fusion(combined)\n",
        "\n",
        "model = MultimodalModel(tabular_size=len(tabular_features))\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CltHoE83msyj",
        "outputId": "061e3b10-2000-4951-e3c9-fd25fcc79bc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 149MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultimodalModel(\n",
            "  (cnn): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (tabular_net): Sequential(\n",
            "    (0): Linear(in_features=20, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (fusion): Sequential(\n",
            "    (0): Linear(in_features=576, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allow slightly corrupted PNGs [web:176]\n",
        "\n",
        "class RobustHouseDataset(Dataset):\n",
        "    def __init__(self, df, tabular_data, transform=None):\n",
        "        self.df\n"
      ],
      "metadata": {
        "id": "b1XVnQvepAPB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE ROBUST DATASET + TRAINING\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allow corrupted PNGs [web:192][web:194]\n",
        "\n",
        "# Robust dataset that skips BAD images\n",
        "class RobustHouseDataset(Dataset):\n",
        "    def __init__(self, df, tabular_data, transform=None):\n",
        "        self.df = df\n",
        "        self.tabular = tabular_data\n",
        "        self.transform = transform\n",
        "        self.valid_indices = []\n",
        "\n",
        "        # Pre-filter valid images\n",
        "        print(\"Checking images...\")\n",
        "        for i in tqdm(range(len(df))):\n",
        "            try:\n",
        "                img_path = df.iloc[i]['image_path']\n",
        "                with Image.open(img_path) as img:\n",
        "                    img.verify()  # Fast check\n",
        "                self.valid_indices.append(i)\n",
        "            except:\n",
        "                pass  # Skip corrupted\n",
        "\n",
        "        print(f\"Valid images: {len(self.valid_indices)}/{len(df)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.valid_indices[idx]\n",
        "        img_path = self.df.iloc[real_idx]['image_path']\n",
        "\n",
        "        # Safe image load\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "        except:\n",
        "            # Fallback: black image\n",
        "            image = torch.zeros(3, 224, 224)\n",
        "\n",
        "        tabular = torch.FloatTensor(self.tabular[real_idx])\n",
        "        price = torch.FloatTensor([self.df.iloc[real_idx]['price']])\n",
        "        return image, tabular, price\n",
        "\n",
        "# Recreate dataset\n",
        "dataset = RobustHouseDataset(df_train_valid, X_tab_scaled, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)  # Smaller batch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox0qipM69_6U",
        "outputId": "586722ee-e976-408d-da1c-43cf1b732aba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16209/16209 [1:29:20<00:00,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid images: 16208/16209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using: {device}\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "total_loss = 0\n",
        "for batch_idx, (images, tabular, prices) in enumerate(tqdm(dataloader)):\n",
        "    images, tabular, prices = images.to(device), tabular.to(device), prices.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    pred_prices = model(images, tabular)\n",
        "    loss = criterion(pred_prices.squeeze(), prices.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    if batch_idx % 20 == 0:\n",
        "        print(f'Batch {batch_idx}, Loss: {loss.item():.2f}')\n",
        "\n",
        "    if batch_idx >= 200:  # ~3200 samples\n",
        "        break\n",
        "\n",
        "print(f\"Avg loss: {total_loss/len(dataloader):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOMzrkW4AwWb",
        "outputId": "538a60a1-324e-4a38-cd3b-f934c7cef827"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1013 [00:06<1:45:30,  6.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0, Loss: 516811718656.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 21/1013 [01:31<1:08:53,  4.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20, Loss: 409796411392.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 41/1013 [02:55<1:08:50,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40, Loss: 326251479040.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 61/1013 [04:20<1:10:19,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60, Loss: 245878882304.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 81/1013 [05:43<1:06:59,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 80, Loss: 220616163328.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 101/1013 [07:06<1:05:50,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 100, Loss: 182794895360.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 121/1013 [08:30<1:05:15,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120, Loss: 137432260608.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 141/1013 [09:53<1:03:32,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 140, Loss: 79109472256.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 161/1013 [11:17<1:02:20,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 160, Loss: 31241062400.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 181/1013 [12:41<1:00:46,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 180, Loss: 41616293888.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 200/1013 [14:05<57:17,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 200, Loss: 16115107840.00\n",
            "Avg loss: 48715114748.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}